{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8951,"status":"ok","timestamp":1700390005021,"user":{"displayName":"Tobias Maier","userId":"04101773763729020426"},"user_tz":-60},"id":"9QSMll3GYCza","outputId":"e98386ac-eae0-4328-de8f-bfaf703849d0"},"outputs":[],"source":["!pip install ucimlrepo pandas matplotlib scikit-learn"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1403,"status":"ok","timestamp":1700390023210,"user":{"displayName":"Tobias Maier","userId":"04101773763729020426"},"user_tz":-60},"id":"kXr2pDoPspfX"},"outputs":[],"source":["# ------- Import Dataset -------------------\n","\n","from ucimlrepo import fetch_ucirepo\n","\n","# fetch dataset\n","air_quality = fetch_ucirepo(id=360)\n","\n","# data (as pandas dataframes)\n","X = air_quality.data.features\n","y = air_quality.data.targets # unused?\n","\n","# print(air_quality.metadata)\n","# print(air_quality.variables)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1085,"status":"ok","timestamp":1700390043791,"user":{"displayName":"Tobias Maier","userId":"04101773763729020426"},"user_tz":-60},"id":"b0PnvB3KT8t8"},"outputs":[],"source":["# Combine Date and Time into a single DateTime column -> only 14 features\n","import pandas as pd\n","\n","X['DateTime'] = pd.to_datetime(X['Date'] + ' ' + X['Time']) # Format (JJJJ-MM-DD HH:MM:SS, e.g.: 2004-03-10 18:00:00)\n","X = X.set_index('DateTime')\n","X.drop(['Date', 'Time'], axis=1, inplace=True)  # Remove the original Date and Time columns"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":254,"status":"ok","timestamp":1700390048727,"user":{"displayName":"Tobias Maier","userId":"04101773763729020426"},"user_tz":-60},"id":"c-jVNDUkr1sa"},"outputs":[],"source":["# Replace all -200 values with 0\n","\n","X.replace(-200, 0, inplace=True)\n","X.replace(-200.0, 0, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Replace all -200 values with 0\n","import numpy as np\n","X.replace(-200, np.nan, inplace=True)\n","X.replace(-200.0, np.nan, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X.fillna(method='ffill', inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ectLJQg9x69m"},"outputs":[],"source":["# X.rename(columns={'PT08.S1(CO)': 'CO(PT08.S1)'})\n","# X.rename(columns={'PT08.S2(NMHC)': 'NMHC(PT08.S2)'})\n","# X.rename(columns={'PT08.S3(NOx)': 'NOx(PT08.S3)'})\n","# X.rename(columns={'PT08.S4(NO2)': 'NO2(PT08.S4)'})\n","# X.rename(columns={'PT08.S5(O3)': 'O3(PT08.S5)'})"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1700391926623,"user":{"displayName":"Tobias Maier","userId":"04101773763729020426"},"user_tz":-60},"id":"_PbEnrspmrQi"},"outputs":[],"source":["# Create second numpy dataframe without \"-200\" values\n","import numpy as np\n","X2 = X.copy()\n","X2.replace(-200, np.nan, inplace=True)\n","X2.replace(-200.0, np.nan, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":255,"status":"ok","timestamp":1700390056581,"user":{"displayName":"Tobias Maier","userId":"04101773763729020426"},"user_tz":-60},"id":"W4kAzByeUAe6","outputId":"5704e61c-a1c0-4b9b-827d-bd8792238308"},"outputs":[],"source":["pd.set_option('display.width', 1000)\n","print(X.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wPYN3qYaUEyb"},"outputs":[],"source":["# Plot all features over a Date-Time axis\n","import matplotlib.pyplot as plt\n","\n","for feature in X.columns:\n","    plt.figure(figsize=(23, 4))\n","    plt.plot(X.index, X[feature])\n","    plt.title(feature)\n","    plt.xlabel('DateTime')\n","    plt.ylabel('Value')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tjAn8spPU7Ls"},"outputs":[],"source":["# Plot two features together over a DateTime axis\n","# Observation: The sensor measuring the same values differ in amplitude -> maybe need to be normalized\n","feature_pairs = [\n","    ('CO(GT)', 'PT08.S1(CO)'),      # Carbon Monoxid\n","    ('NMHC(GT)', 'PT08.S2(NMHC)'),  # Non Metanic Hyrdo Carbons\n","    ('NOx(GT)', 'PT08.S3(NOx)'),    # Nitrogen Oxides -> Nitric Oxide (NO) + Nitrogen Dioxide (NO2)\n","    ('NO2(GT)', 'PT08.S4(NO2)'),    # Nitrogen Dioxide\n","]\n","\n","for feature1, feature2 in feature_pairs:\n","  plt.figure(figsize=(20, 4))\n","  plt.plot(X.index, X[feature1], label=feature1)\n","  plt.plot(X.index, X[feature2], label=feature2)\n","  plt.title(f'{feature1} and {feature2} over Time')\n","  plt.xlabel('DateTime')\n","  plt.ylabel('Value')\n","  plt.legend()\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NtF-7aPrpYIl"},"outputs":[],"source":["# Plot two features together over a DateTime axis but normalize them and remove \"-200\" values\n","# Observation: After normalizing the pair features, the two sensors often differ from each other. Here is probaly some kind of systemic error in the features. -> maybe temperatur dependat???\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import MinMaxScaler\n","import pandas as pd\n","\n","feature_pairs = [\n","    ('CO(GT)', 'PT08.S1(CO)'),\n","    ('NMHC(GT)', 'PT08.S2(NMHC)'),\n","    ('NOx(GT)', 'PT08.S3(NOx)'),\n","    ('NO2(GT)', 'PT08.S4(NO2)'),\n","]\n","\n","# Create a Min-Max Scaler instance\n","scaler = MinMaxScaler()\n","\n","for feature1, feature2 in feature_pairs:\n","    plt.figure(figsize=(20, 4))\n","\n","    # Select the features and drop NaN values for consistent scaling\n","    pair_data = X2[[feature1, feature2]].dropna()\n","\n","    # Apply Min-Max scaling\n","    scaled_data = scaler.fit_transform(pair_data)\n","\n","    # Plot the normalized features\n","    plt.plot(X2.index[X2.index.isin(pair_data.index)], scaled_data[:, 0], label=f'Normalized {feature1}')\n","    plt.plot(X2.index[X2.index.isin(pair_data.index)], scaled_data[:, 1], label=f'Normalized {feature2}')\n","    plt.title(f'Normalized {feature1} and {feature2} over Time')\n","    plt.xlabel('DateTime')\n","    plt.ylabel('Normalized Value')\n","    plt.legend()\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ADXly5pquxrR"},"outputs":[],"source":["# Plot all features within a 24h range while averaging over a year\n","# Observation: -> 7-10 am spike and 5-8 pm spike -> most trafic\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","X2['Hour'] = X2.index.hour\n","hourly_means = X2.groupby('Hour').mean()\n","\n","for feature in hourly_means.columns:\n","    if feature != 'Hour':  # Exclude the hour column from plotting\n","        plt.figure(figsize=(23, 4))\n","        plt.plot(hourly_means.index, hourly_means[feature], marker='o')  # Changed to line plot with markers\n","        plt.title(f'{feature}')\n","        plt.xlabel('Hour of Day')\n","        plt.ylabel('Average Value')\n","        plt.xticks(range(24))  # Ensure all hours are shown\n","        plt.grid(True)  # Optional: Adds a grid for better readability\n","        plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wHWQ_uSyz8po"},"outputs":[],"source":["# Plot all recorded days and take an average of 24h\n","# Observation: There are lots of small round peaks. These are the weeks\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","# Assuming X is your DataFrame and the index is a datetime index\n","# Resample the data by day and calculate the mean\n","daily_means = X.resample('D').mean()\n","\n","# Plotting\n","for feature in daily_means.columns:\n","    plt.figure(figsize=(23, 4))\n","    plt.plot(daily_means.index, daily_means[feature], marker='o')\n","    plt.title(f'Daily Average of {feature}')\n","    plt.xlabel('Day')\n","    plt.ylabel('Average Value')\n","    plt.xticks(rotation=45)  # Rotate the x-axis labels for better readability\n","    plt.grid(True)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T30cIcc1jHnT"},"outputs":[],"source":["# Plot all features within 24h, while seperating week day (aferage over 52 values/weeks -> 24h * 7days)\n","# Observation: Sunday is the least polution, Saturday is also less compared to all the other days.\n","# Observation: One of the two NOx sensor shows inverse values for the week days compared to the other NOx sensor and all the other sensors covering polution -> sunday most, friday least -> WHY???\n","import matplotlib.pyplot as plt\n","\n","X2['DayOfWeek'] = X2.index.dayofweek\n","daily_means = X2.groupby('DayOfWeek').mean()\n","\n","import matplotlib.pyplot as plt\n","\n","days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n","\n","for feature in daily_means.columns:\n","    plt.figure(figsize=(10, 4))\n","    plt.plot(days, daily_means[feature], marker='o')\n","    plt.title(f'Average Values of {feature} Over the Week')\n","    plt.xlabel('Day of Week')\n","    plt.ylabel('Average Value')\n","    plt.xticks(days)\n","    plt.grid(True)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9VrJAMkxkGCM"},"outputs":[],"source":["# Plot an average of for each feature over an hour axis but seperate by week day\n","# Observation: Spike between 7-9 am and 5-8 pm, sunday and saturday less\n","# Observation: PT08.S3(NOx) Sunday the most polution -> further indication that high and low values are reversed!!!\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","X2['DayOfWeek'] = X2.index.dayofweek\n","X2['Hour'] = X2.index.hour\n","\n","daily_hourly_means = X2.groupby(['DayOfWeek', 'Hour']).mean()\n","\n","days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n","\n","for feature in daily_hourly_means.columns:\n","    plt.figure(figsize=(15, 5))\n","    for day in range(7):  # 0 is Monday, 6 is Sunday\n","        day_data = daily_hourly_means.loc[day]\n","        plt.plot(np.arange(24), day_data[feature], label=days[day], marker='o')\n","    plt.title(f'Hourly Average Values of {feature} Over the Week')\n","    plt.xlabel('Hour of Day')\n","    plt.ylabel('Average Value')\n","    plt.xticks(np.arange(24))\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-vNYaAa9mWI_"},"outputs":[],"source":["# Plot an average of each feature for each week of the year -> maybe more on christmas...\n","# Observation: in the winter-month, when the temperatur is lower, the polution is higher\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","\n","\n","# Calculate WeekOfYear and ensure it's an integer\n","X2['WeekOfYear'] = X2.index.isocalendar().week.astype(int)\n","weekly_means = X2.groupby('WeekOfYear').mean()\n","\n","# Plotting\n","for feature in weekly_means.columns:\n","    plt.figure(figsize=(23, 4))\n","    plt.plot(weekly_means.index, weekly_means[feature], marker='o')\n","    plt.title(f'Average Weekly Values of {feature}')\n","    plt.xlabel('Week of the Year')\n","    plt.ylabel('Average Value')\n","\n","    # Handling x-ticks\n","    x_ticks = weekly_means.index.unique()\n","    plt.xticks(x_ticks, rotation=45)  # Set x-ticks to unique values of WeekOfYear\n","\n","    plt.grid(True)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3167,"status":"ok","timestamp":1700391536954,"user":{"displayName":"Tobias Maier","userId":"04101773763729020426"},"user_tz":-60},"id":"MKcJ8maL7N29","outputId":"82e274e0-4c53-4f07-ac2d-a302854114bd"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","feature_pairs = [\n","    ('CO(GT)', 'PT08.S1(CO)'),      # Carbon Monoxide\n","    ('NMHC(GT)', 'PT08.S2(NMHC)'),  # Non-Metanic Hydro Carbons\n","    ('NOx(GT)', 'PT08.S3(NOx)'),    # Nitrogen Oxides\n","    ('NO2(GT)', 'PT08.S4(NO2)'),    # Nitrogen Dioxide\n","]\n","\n","# Define the rolling window size\n","window_size = 30  # e.g., 30 days\n","\n","for feature1, feature2 in feature_pairs:\n","    plt.figure(figsize=(20, 4))\n","\n","    # Calculate rolling correlation\n","    rolling_corr = X[[feature1, feature2]].rolling(window=window_size).corr().unstack()[feature1][feature2]\n","\n","    # Plot the rolling correlation\n","    plt.plot(rolling_corr, label=f'Rolling Correlation ({window_size}-day window)')\n","    plt.title(f'Rolling Correlation between {feature1} and {feature2} over Time')\n","    plt.xlabel('DateTime')\n","    plt.ylabel('Rolling Correlation')\n","    plt.legend()\n","    plt.show()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOHmD8NFdD+tHQNfkc7nEIJ","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
