{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ucimlrepo pandas scikit-learn tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Import Dataset -------------------\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset\n",
    "air_quality = fetch_ucirepo(id=360)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = air_quality.data.features\n",
    "y = air_quality.data.targets # unused?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Date and Time into a single DateTime column -> only 14 features\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X['DateTime'] = pd.to_datetime(X['Date'] + ' ' + X['Time']) # Format (JJJJ-MM-DD HH:MM:SS, e.g.: 2004-03-10 18:00:00)\n",
    "X = X.set_index('DateTime')\n",
    "X.drop(['Date', 'Time'], axis=1, inplace=True)  # Remove the original Date and Time columns\n",
    "X.replace(-200, np.nan, inplace=True)\n",
    "X.replace(-200.0, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 1000)\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert PT08.S3(NOx)\n",
    "X['PT08.S3(NOx)'] = -1 * X['PT08.S3(NOx)']  # Reversing the sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize the Min-Max Scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Select only the columns to be scaled\n",
    "features_to_scale = X.columns  # As 'DateTime' is an index, it won't be included\n",
    "\n",
    "# Apply the scaler to the features\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X[features_to_scale]), columns=features_to_scale, index=X.index)\n",
    "\n",
    "# Now X_scaled contains the normalized data, with 'DateTime' as the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changes nothing for linear regression -> forward fill NA values\n",
    "X_scaled.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define LSTM Mode\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        x = data[i:(i+seq_length)]\n",
    "        y = data[i+seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "#Prepere our data \n",
    "# data = np.array([[i+j] for i in range (100) for j in range (2)])\n",
    "data = X\n",
    "\n",
    "look_back = 15\n",
    "xs, ys = create_sequences(data, look_back)\n",
    "\n",
    "#Reshape of the input\n",
    "xs = np.reshape(xs, (xs.shape[0], xs.shape[1], 1))\n",
    "\n",
    "#Define LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, activation='relu', input_shape=(look_back, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "#Fit the model\n",
    "model.fit(xs, ys, epochs = 100, batch_size=1, verbose =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM prepare Data\n",
    "import numpy as np\n",
    "def create_sequences(data, seq_length):\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        x = data.iloc[i:(i+seq_length)]\n",
    "        y = data.iloc[i+seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "\n",
    "    return np.array([x.values for x in xs]), np.array(ys)\n",
    "\n",
    "# Define sequence length\n",
    "seq_length = 5  # Example: 5 time steps\n",
    "\n",
    "# Prepare the sequences using X_scaled\n",
    "X, y = create_sequences(X_scaled, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:(i + seq_length)]\n",
    "        y = data[i + seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Define sequence length\n",
    "seq_length = 5  # Example: 5 time steps\n",
    "\n",
    "# Prepare the sequences\n",
    "X_s, y_s = create_sequences(X_scaled, seq_length)\n",
    "\n",
    "# Split the data into training and testing (customize the ratio as needed)\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X_s[:train_size], X_s[train_size:]\n",
    "y_train, y_test = y_s[:train_size], y_s[train_size:]\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(50, activation='relu', input_shape=(seq_length, X.shape[2])),\n",
    "    Dense(y.shape[1])\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM prepare Model\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "n_features = X_scaled.shape[1]  # Number of features\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(seq_length, n_features)))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(n_features))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM train Model\n",
    "model.fit(X, y, epochs=30, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM predict with Model\n",
    "last_sequence = X_scaled[-seq_length:]\n",
    "last_sequence = np.expand_dims(last_sequence.values, axis=0)\n",
    "\n",
    "predicted = model.predict(last_sequence)\n",
    "\n",
    "# Inverse transform the predicted value\n",
    "predicted = scaler.inverse_transform(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Assuming df is your original DataFrame and model is your trained LSTM model\n",
    "\n",
    "# Convert your input DateTime to a format that matches your DataFrame\n",
    "input_datetime = datetime.strptime('2005-04-11 18:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Find the index of the input DateTime\n",
    "index = X.index.get_loc(input_datetime)\n",
    "\n",
    "# Extract the sequence leading up to the input DateTime\n",
    "sequence = X.iloc[index-seq_length:index].drop('DateTime', axis=1)\n",
    "\n",
    "# Normalize the sequence\n",
    "sequence_scaled = scaler.transform(sequence)\n",
    "\n",
    "# Reshape the sequence for the LSTM (adding sample dimension)\n",
    "sequence_scaled = np.expand_dims(sequence_scaled, axis=0)\n",
    "\n",
    "# Make the prediction\n",
    "predicted_value_scaled = model.predict(sequence_scaled)\n",
    "\n",
    "# Inverse scaling (if necessary)\n",
    "predicted_value = scaler.inverse_transform(predicted_value_scaled)\n",
    "\n",
    "# The predicted value\n",
    "print(predicted_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# Fetch dataset\n",
    "air_quality = fetch_ucirepo(id=360)\n",
    "\n",
    "# Data as pandas DataFrame\n",
    "X = air_quality.data.features\n",
    "# y = air_quality.data.targets # This can be used if you have specific target variables\n",
    "\n",
    "# Convert to DateTime and set as index\n",
    "X['DateTime'] = pd.to_datetime(X['Date'] + ' ' + X['Time'])\n",
    "X = X.set_index('DateTime')\n",
    "X.drop(['Date', 'Time'], axis=1, inplace=True)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns, index=X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create sequences\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data.iloc[i:(i + seq_length)].values\n",
    "        y = data.iloc[i + seq_length].values\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Define sequence length\n",
    "seq_length = 5  # Example: 5 time steps\n",
    "\n",
    "# Prepare the sequences\n",
    "X_sequences, y_sequences = create_sequences(X_scaled, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sequences, y_sequences, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dense(y_train.shape[1])\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=40, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_sequence = X.iloc[-seq_length:]\n",
    "\n",
    "# Convert the sequence to a NumPy array\n",
    "last_sequence = last_sequence.values\n",
    "\n",
    "# Reshape the sequence to match the input shape for the LSTM\n",
    "# The shape should be (1, seq_length, number_of_features)\n",
    "last_sequence = last_sequence.reshape((1, seq_length, last_sequence.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's assume `last_sequence` is your input sequence leading up to the time of prediction\n",
    "# and `scaler` is the MinMaxScaler instance used for normalizing the data\n",
    "\n",
    "# Normalize the input\n",
    "last_sequence_scaled = scaler.transform(last_sequence)\n",
    "\n",
    "# Reshape the input for LSTM\n",
    "# LSTM expects input shape [samples, time steps, features]\n",
    "last_sequence_scaled = last_sequence_scaled.reshape((1, last_sequence_scaled.shape[0], last_sequence_scaled.shape[1]))\n",
    "\n",
    "# Make the prediction\n",
    "predicted_values_scaled = model.predict(last_sequence_scaled)\n",
    "\n",
    "# Inverse transform the prediction to original scale\n",
    "predicted_values = scaler.inverse_transform(predicted_values_scaled)\n",
    "\n",
    "# predicted_values now contains the prediction for the specified future time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Print the last date\n",
    "print(\"Last date in the dataset:\", X.index[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.loc[X.index[-1], 'CO(GT)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "# Assuming 'model' is your trained LSTM model\n",
    "# And 'last_known_sequence' is the last sequence from your dataset (from end of 2005)\n",
    "\n",
    "# Normalize last_known_sequence as done during training\n",
    "# ...\n",
    "\n",
    "last_known_sequence = X.iloc[-seq_length:].values\n",
    "\n",
    "# Make sure to reshape it to the format expected by the LSTM model\n",
    "# (1, seq_length, number_of_features)\n",
    "last_known_sequence = last_known_sequence.reshape((1, seq_length, X.shape[1]))\n",
    "\n",
    "# Reshape for the model\n",
    "current_sequence = last_known_sequence.reshape((1, seq_length, 13))\n",
    "\n",
    "# Initialize the current prediction date\n",
    "current_prediction_date = pd.to_datetime(\"2005-04-02 14:00:00\")  # Adjust to your dataset's last date\n",
    "\n",
    "# Desired prediction date\n",
    "desired_date = pd.to_datetime(\"2005-04-04 14:00:00\")\n",
    "\n",
    "# Iterate predictions\n",
    "while current_prediction_date < desired_date:\n",
    "    # Predict the next step\n",
    "    next_step_prediction = model.predict(current_sequence)\n",
    "    \n",
    "    # Update the sequence: remove the oldest step and add the predicted step\n",
    "    current_sequence = np.roll(current_sequence, -1, axis=1)\n",
    "    current_sequence[0, -1, :] = next_step_prediction\n",
    "\n",
    "    # Update the prediction date (assuming hourly data, adjust as needed)\n",
    "    current_prediction_date += timedelta(hours=1)\n",
    "\n",
    "# The last prediction is for the desired_date\n",
    "final_prediction = current_sequence[0, -1, :]\n",
    "print(final_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM \n",
    "#Define LSTM Mode\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "def create_sequences(data, feature, seq_length):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        x = data[feature].iloc[i:(i+seq_length)]\n",
    "        y = data[feature].iloc[i+seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Choose a feature to predict\n",
    "feature = 'CO(GT)'\n",
    "\n",
    "# Create sequences from your data\n",
    "xs, ys = create_sequences(X, feature, seq_length)\n",
    "\n",
    "# Reshape the input to be [samples, time steps, features]\n",
    "xs = np.reshape(xs, (xs.shape[0], xs.shape[1], 1))\n",
    "\n",
    "#Define LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, activation='relu', input_shape=(look_back, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "#Fit the model\n",
    "model.fit(xs, ys, epochs = 10, batch_size=1, verbose =2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
