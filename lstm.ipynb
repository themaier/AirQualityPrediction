{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ucimlrepo numpy pandas scikit-learn tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Import Dataset -------------------\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset\n",
    "air_quality = fetch_ucirepo(id=360)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = air_quality.data.features\n",
    "y = air_quality.data.targets # unused?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Date and Time into a single DateTime column -> only 14 features\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X['DateTime'] = pd.to_datetime(X['Date'] + ' ' + X['Time']) # Format (JJJJ-MM-DD HH:MM:SS, e.g.: 2004-03-10 18:00:00)\n",
    "X = X.set_index('DateTime')\n",
    "X.drop(['Date', 'Time'], axis=1, inplace=True)  # Remove the original Date and Time columns\n",
    "X.replace(-200, np.nan, inplace=True)\n",
    "X.replace(-200.0, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 1000)\n",
    "print(X.head())\n",
    "print(X.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only one feature\n",
    "df = X[['CO(GT)']]\n",
    "# df = df.interpolate()\n",
    "# df = df.interpolate(method='spline', order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_interpolate(row):\n",
    "    if pd.isna(row['CO(GT)']):\n",
    "        # Get similar instances from the data (e.g., same hour from previous days)\n",
    "        similar_instances = df[(df.index.hour == row.name.hour) & ~df['CO(GT)'].isna()]\n",
    "        return similar_instances['CO(GT)'].mean()\n",
    "    else:\n",
    "        return row['CO(GT)']\n",
    "\n",
    "df['CO(GT)'] = df.apply(custom_interpolate, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(23, 4))\n",
    "plt.plot(df.index, df.values)\n",
    "plt.title('CO(GT)')\n",
    "plt.xlabel('DateTime')\n",
    "plt.ylabel('Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 1\n",
    "df = df.reshape((df.shape[0], df.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data = scaler.fit_transform(df)\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data)-seq_length):\n",
    "        x = data[i:i+seq_length]\n",
    "        y = data[i+seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df.index, data, label='Scaled Data')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Scaled Value')\n",
    "plt.title('Scaled Time Series Data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM data for daily (24h) seq_length\n",
    "total_rows = len(data)\n",
    "split_point = int(total_rows * 0.8)  # 80% for training, 20% for validation\n",
    "\n",
    "train_data = data[:split_point]\n",
    "validation_data = data[split_point:]\n",
    "\n",
    "seq_length = 24 # 24h cycle\n",
    "X_train, y_train = create_sequences(train_data, seq_length)\n",
    "X_validate, y_validate = create_sequences(validation_data, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM data for weekly (24h*7) seq_length\n",
    "total_rows = len(data)\n",
    "split_point = int(total_rows * 0.8)  # 80% for training, 20% for validation\n",
    "\n",
    "train_data = data[:split_point]\n",
    "validation_data = data[split_point:]\n",
    "\n",
    "seq_length = 24*7 # 24h cycle\n",
    "X_train, y_train = create_sequences(train_data, seq_length)\n",
    "X_validate, y_validate = create_sequences(validation_data, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM training for with seq_length from cell above (24h vs 24h*7)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(LSTM(70, activation='relu', input_shape=(seq_length, 1)))\n",
    "model2.add(Dropout(0.4))\n",
    "model2.add(Dense(1, activation='linear'))\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model2.fit(X_train, y_train, epochs=30, batch_size=32, verbose =1, validation_data=(X_validate, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM training for with seq_length from cell above (24h vs 24h*7)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(80, activation='relu', input_shape=(seq_length, 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=32, verbose =1, validation_data=(X_validate, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show first and last DateTime\n",
    "print(df.index[-1])\n",
    "print(df.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "\n",
    "# Function to predict future values and store them for plotting\n",
    "def predict_and_store_future_values(start_date, end_date, model, last_sequence, scaler):\n",
    "    current_date = start_date\n",
    "    predictions = []\n",
    "    dates = []\n",
    "    while current_date <= end_date:\n",
    "        current_sequence = last_sequence.reshape((1, seq_length, 1))\n",
    "        next_prediction = model.predict(current_sequence)[0]\n",
    "        last_sequence = np.roll(last_sequence, -1)\n",
    "        last_sequence[-1] = next_prediction\n",
    "        predictions.append(scaler.inverse_transform([next_prediction])[0][0])\n",
    "        dates.append(current_date)\n",
    "        current_date += timedelta(hours=1)\n",
    "    return dates, predictions\n",
    "\n",
    "# Predict for a specific future date and store the values\n",
    "start_date = pd.to_datetime(\"2005-04-06 14:00:00\") #\"df.index[-1])  # Last date in your dataset 2005-04-04 14:00:00\n",
    "end_date = pd.to_datetime(\"2005-05-08 16:00:00\")\n",
    "last_sequence = data[-seq_length:]  # Last known sequence from your dataset\n",
    "\n",
    "dates, predicted_values = predict_and_store_future_values(start_date, end_date, model2, last_sequence, scaler)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(dates, predicted_values, label='Predicted Values')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Predicted Values from Last Known Date to Future Date')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
