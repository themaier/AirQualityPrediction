{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ucimlrepo in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (0.0.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (1.3.2)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (2.15.0)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.22.4)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.54.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.41.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.28.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\tobias\\appdata\\roaming\\python\\python310\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install ucimlrepo pandas scikit-learn tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Import Dataset -------------------\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset\n",
    "air_quality = fetch_ucirepo(id=360)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = air_quality.data.features\n",
    "y = air_quality.data.targets # unused?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Date and Time into a single DateTime column -> only 14 features\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X['DateTime'] = pd.to_datetime(X['Date'] + ' ' + X['Time']) # Format (JJJJ-MM-DD HH:MM:SS, e.g.: 2004-03-10 18:00:00)\n",
    "X = X.set_index('DateTime')\n",
    "X.drop(['Date', 'Time'], axis=1, inplace=True)  # Remove the original Date and Time columns\n",
    "X.replace(-200, np.nan, inplace=True)\n",
    "X.replace(-200.0, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 1000)\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert PT08.S3(NOx)\n",
    "X['PT08.S3(NOx)'] = -1 * X['PT08.S3(NOx)']  # Reversing the sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize the Min-Max Scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Select only the columns to be scaled\n",
    "features_to_scale = X.columns  # As 'DateTime' is an index, it won't be included\n",
    "\n",
    "# Apply the scaler to the features\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X[features_to_scale]), columns=features_to_scale, index=X.index)\n",
    "\n",
    "# Now X_scaled contains the normalized data, with 'DateTime' as the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changes nothing for linear regression -> forward fill NA values\n",
    "X_scaled.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define LSTM Mode\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        x = data[i:(i+seq_length)]\n",
    "        y = data[i+seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "#Prepere our data \n",
    "# data = np.array([[i+j] for i in range (100) for j in range (2)])\n",
    "data = X\n",
    "\n",
    "look_back = 15\n",
    "xs, ys = create_sequences(data, look_back)\n",
    "\n",
    "#Reshape of the input\n",
    "xs = np.reshape(xs, (xs.shape[0], xs.shape[1], 1))\n",
    "\n",
    "#Define LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, activation='relu', input_shape=(look_back, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "#Fit the model\n",
    "model.fit(xs, ys, epochs = 100, batch_size=1, verbose =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM prepare Data\n",
    "import numpy as np\n",
    "def create_sequences(data, seq_length):\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        x = data.iloc[i:(i+seq_length)]\n",
    "        y = data.iloc[i+seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "\n",
    "    return np.array([x.values for x in xs]), np.array(ys)\n",
    "\n",
    "# Define sequence length\n",
    "seq_length = 5  # Example: 5 time steps\n",
    "\n",
    "# Prepare the sequences using X_scaled\n",
    "X, y = create_sequences(X_scaled, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:(i + seq_length)]\n",
    "        y = data[i + seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Define sequence length\n",
    "seq_length = 5  # Example: 5 time steps\n",
    "\n",
    "# Prepare the sequences\n",
    "X_s, y_s = create_sequences(X_scaled, seq_length)\n",
    "\n",
    "# Split the data into training and testing (customize the ratio as needed)\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X_s[:train_size], X_s[train_size:]\n",
    "y_train, y_test = y_s[:train_size], y_s[train_size:]\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(50, activation='relu', input_shape=(seq_length, X.shape[2])),\n",
    "    Dense(y.shape[1])\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM prepare Model\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "n_features = X_scaled.shape[1]  # Number of features\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(seq_length, n_features)))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(n_features))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM train Model\n",
    "model.fit(X, y, epochs=30, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM predict with Model\n",
    "last_sequence = X_scaled[-seq_length:]\n",
    "last_sequence = np.expand_dims(last_sequence.values, axis=0)\n",
    "\n",
    "predicted = model.predict(last_sequence)\n",
    "\n",
    "# Inverse transform the predicted value\n",
    "predicted = scaler.inverse_transform(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Assuming df is your original DataFrame and model is your trained LSTM model\n",
    "\n",
    "# Convert your input DateTime to a format that matches your DataFrame\n",
    "input_datetime = datetime.strptime('2005-04-11 18:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Find the index of the input DateTime\n",
    "index = X.index.get_loc(input_datetime)\n",
    "\n",
    "# Extract the sequence leading up to the input DateTime\n",
    "sequence = X.iloc[index-seq_length:index].drop('DateTime', axis=1)\n",
    "\n",
    "# Normalize the sequence\n",
    "sequence_scaled = scaler.transform(sequence)\n",
    "\n",
    "# Reshape the sequence for the LSTM (adding sample dimension)\n",
    "sequence_scaled = np.expand_dims(sequence_scaled, axis=0)\n",
    "\n",
    "# Make the prediction\n",
    "predicted_value_scaled = model.predict(sequence_scaled)\n",
    "\n",
    "# Inverse scaling (if necessary)\n",
    "predicted_value = scaler.inverse_transform(predicted_value_scaled)\n",
    "\n",
    "# The predicted value\n",
    "print(predicted_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# Fetch dataset\n",
    "air_quality = fetch_ucirepo(id=360)\n",
    "\n",
    "# Data as pandas DataFrame\n",
    "X = air_quality.data.features\n",
    "# y = air_quality.data.targets # This can be used if you have specific target variables\n",
    "\n",
    "# Convert to DateTime and set as index\n",
    "X['DateTime'] = pd.to_datetime(X['Date'] + ' ' + X['Time'])\n",
    "X = X.set_index('DateTime')\n",
    "X.drop(['Date', 'Time'], axis=1, inplace=True)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns, index=X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create sequences\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data.iloc[i:(i + seq_length)].values\n",
    "        y = data.iloc[i + seq_length].values\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Define sequence length\n",
    "seq_length = 5  # Example: 5 time steps\n",
    "\n",
    "# Prepare the sequences\n",
    "X_sequences, y_sequences = create_sequences(X_scaled, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sequences, y_sequences, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dense(y_train.shape[1])\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=40, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_sequence = X.iloc[-seq_length:]\n",
    "\n",
    "# Convert the sequence to a NumPy array\n",
    "last_sequence = last_sequence.values\n",
    "\n",
    "# Reshape the sequence to match the input shape for the LSTM\n",
    "# The shape should be (1, seq_length, number_of_features)\n",
    "last_sequence = last_sequence.reshape((1, seq_length, last_sequence.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's assume `last_sequence` is your input sequence leading up to the time of prediction\n",
    "# and `scaler` is the MinMaxScaler instance used for normalizing the data\n",
    "\n",
    "# Normalize the input\n",
    "last_sequence_scaled = scaler.transform(last_sequence)\n",
    "\n",
    "# Reshape the input for LSTM\n",
    "# LSTM expects input shape [samples, time steps, features]\n",
    "last_sequence_scaled = last_sequence_scaled.reshape((1, last_sequence_scaled.shape[0], last_sequence_scaled.shape[1]))\n",
    "\n",
    "# Make the prediction\n",
    "predicted_values_scaled = model.predict(last_sequence_scaled)\n",
    "\n",
    "# Inverse transform the prediction to original scale\n",
    "predicted_values = scaler.inverse_transform(predicted_values_scaled)\n",
    "\n",
    "# predicted_values now contains the prediction for the specified future time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Print the last date\n",
    "print(\"Last date in the dataset:\", X.index[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.loc[X.index[-1], 'CO(GT)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "# Assuming 'model' is your trained LSTM model\n",
    "# And 'last_known_sequence' is the last sequence from your dataset (from end of 2005)\n",
    "\n",
    "# Normalize last_known_sequence as done during training\n",
    "# ...\n",
    "\n",
    "last_known_sequence = X.iloc[-seq_length:].values\n",
    "\n",
    "# Make sure to reshape it to the format expected by the LSTM model\n",
    "# (1, seq_length, number_of_features)\n",
    "last_known_sequence = last_known_sequence.reshape((1, seq_length, X.shape[1]))\n",
    "\n",
    "# Reshape for the model\n",
    "current_sequence = last_known_sequence.reshape((1, seq_length, 13))\n",
    "\n",
    "# Initialize the current prediction date\n",
    "current_prediction_date = pd.to_datetime(\"2005-04-02 14:00:00\")  # Adjust to your dataset's last date\n",
    "\n",
    "# Desired prediction date\n",
    "desired_date = pd.to_datetime(\"2005-04-04 14:00:00\")\n",
    "\n",
    "# Iterate predictions\n",
    "while current_prediction_date < desired_date:\n",
    "    # Predict the next step\n",
    "    next_step_prediction = model.predict(current_sequence)\n",
    "    \n",
    "    # Update the sequence: remove the oldest step and add the predicted step\n",
    "    current_sequence = np.roll(current_sequence, -1, axis=1)\n",
    "    current_sequence[0, -1, :] = next_step_prediction\n",
    "\n",
    "    # Update the prediction date (assuming hourly data, adjust as needed)\n",
    "    current_prediction_date += timedelta(hours=1)\n",
    "\n",
    "# The last prediction is for the desired_date\n",
    "final_prediction = current_sequence[0, -1, :]\n",
    "print(final_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM \n",
    "#Define LSTM Mode\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "def create_sequences(data, feature, seq_length):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        x = data[feature].iloc[i:(i+seq_length)]\n",
    "        y = data[feature].iloc[i+seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Choose a feature to predict\n",
    "feature = 'CO(GT)'\n",
    "\n",
    "# Create sequences from your data\n",
    "xs, ys = create_sequences(X, feature, seq_length)\n",
    "\n",
    "# Reshape the input to be [samples, time steps, features]\n",
    "xs = np.reshape(xs, (xs.shape[0], xs.shape[1], 1))\n",
    "\n",
    "#Define LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, activation='relu', input_shape=(look_back, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "#Fit the model\n",
    "model.fit(xs, ys, epochs = 10, batch_size=1, verbose =2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
